{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workshop Week 10: Question Answering\n",
    "\n",
    "#### Please follow the instructions in this code and the workshop Instructor.\n",
    "\n",
    "Types of QA systems:\n",
    "\n",
    "    Extractive QA systems: These systems extract the answer directly from the given text by identifying the relevant section of text that contains the answer.\n",
    "\n",
    "    Abstractive QA systems: These systems generate a new answer by understanding the meaning of the question and synthesizing information from various sources.\n",
    "\n",
    "Classical (before deep neural learning) QA systems:\n",
    "\n",
    "    Information Retrieval based QA systems: These systems use information retrieval techniques to search for relevant documents and retrieve the most relevant answers.\n",
    "\n",
    "    Knowledge Graph based QA systems: These systems represent information in a structured format and use graph-based algorithms to answer questions.\n",
    "\n",
    "    Watson QA system: This system, developed by IBM, uses a combination of natural language processing, machine learning, and information retrieval techniques to answer questions in a wide range of domains.\n",
    "\n",
    "Evaluation of QA and Stanford Question Answering Dataset (SQuAD):\n",
    "\n",
    "SQuAD is a popular dataset used for evaluating QA systems. It consists of a large number of questions and answers, along with the corresponding passages of text that contain the answers. The dataset is used to evaluate the accuracy and performance of different QA systems.\n",
    "\n",
    "Language models for QA systems:\n",
    "\n",
    "    BiDAF (Bidirectional Attention Flow): This model uses a bidirectional attention mechanism to encode the question and the passage and identify the most relevant words and phrases.\n",
    "\n",
    "    Encoder-decoder transformers: These models use transformer networks to encode the input text and generate the output answer.\n",
    "\n",
    "    SpanBERT: This model is an extension of the BERT (Bidirectional Encoder Representations from Transformers) model and uses a span-based approach to answer questions. It considers all possible spans in the input text to generate the final answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51d2168a4fb5479e8ee780759d13ac96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/152 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1231060\\AppData\\Local\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\a1231060\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8108b0047f2d4f1f8d89d2ace9c25d7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/508 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f2aa0cb8d534587a33fc54d2f41c7f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d07b7063085d4e639b1933ea516ed41c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\a1231060\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\a1231060\\AppData\\Local\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81b6ab95a6c4e27b4ee17e13fc87bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\a1231060\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Answer: Paris\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the BiDAF model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "model = AutoModelForQuestionAnswering.from_pretrained('deepset/bert-base-cased-squad2')\n",
    "\n",
    "# Define a sample question and passage\n",
    "question = \"What is the capital of France?\"\n",
    "passage = \"France, officially the French Republic, is a country primarily located in Western Europe, consisting of metropolitan France and several overseas regions and territories. Paris is the capital and most populous city of France.\"\n",
    "\n",
    "# Encode the question and passage using the tokenizer\n",
    "inputs = tokenizer.encode_plus(question, passage, return_tensors='pt', max_length=512, truncation=True, truncation_strategy='only_second')\n",
    "input_ids = inputs['input_ids']\n",
    "token_type_ids = inputs['token_type_ids']\n",
    "attention_mask = inputs['attention_mask']\n",
    "\n",
    "# Pass the encoded input through the BiDAF model\n",
    "outputs = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, return_dict=True)\n",
    "start_logits = outputs.start_logits\n",
    "end_logits = outputs.end_logits\n",
    "\n",
    "# Decode the predicted start and end positions to get the answer\n",
    "start_index = torch.argmax(start_logits)\n",
    "end_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "input_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "answer_tokens = input_ids[0][start_index:end_index]\n",
    "answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "# Skip over any tokens before the start position or after the end position\n",
    "for i, token in enumerate(answer_tokens):\n",
    "    if token == tokenizer.cls_token_id:\n",
    "        start_index += 1\n",
    "    elif token == tokenizer.sep_token_id:\n",
    "        end_index -= 1\n",
    "answer_tokens = input_ids[0][start_index:end_index]\n",
    "\n",
    "# Decode the answer tokens to get the final answer\n",
    "answer = tokenizer.decode(answer_tokens)\n",
    "print(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Construct Q/A system\n",
    "\n",
    "Task Description: In this task, you will be given a set of questions and a corresponding set of passages. Your goal is to use a QA model to find the answer to each question in its corresponding passage.\n",
    "\n",
    "Please review the code to understand it, run the first part, and complete the rest to make a QA system.\n",
    "\n",
    "Then follow the instructions for the workshop Instructor.\n",
    "\n",
    "Instructions for the Instructor (please take this as a suggeston, you can design your own workshop flow):\n",
    "\n",
    "    Begin by introducing the participants to the task and the QA model that will be used. Provide a brief overview of how the model works and how it can be used to find answers to questions.\n",
    "\n",
    "    Divide the participants into small groups, with each group consisting of 2-3 people. Provide each group with a set of questions and a corresponding set of passages.\n",
    "\n",
    "    Instruct the participants to use the QA model to find the answer to each question in its corresponding passage. They should start by encoding the question and passage using the tokenizer, and then pass the encoded input through the QA model to obtain the predicted answer.\n",
    "\n",
    "    Once the participants have obtained the predicted answer, they should decode the answer from the corresponding tokens using the tokenizer, and then compare the predicted answer to the actual answer.\n",
    "\n",
    "    After each group has finished answering all the questions, bring the participants together and review the answers to each question. Discuss any common mistakes or misconceptions that arose during the task, and provide feedback and guidance to help the participants improve their performance.\n",
    "\n",
    "    To wrap up the task, ask the participants to reflect on what they learned and how they can apply this knowledge in their aAsignment 1 or work or studies.\n",
    "    \n",
    "\n",
    "Example Questions and Passages:\n",
    "\n",
    "Question 1: What is the capital of the United States?\n",
    "\n",
    "Passage 1: The capital of the United States is Washington, D.C. It is located on the east coast of the country, and is home to many important government buildings and monuments.\n",
    "\n",
    "Question 2: Who wrote the novel \"To Kill a Mockingbird\"?\n",
    "\n",
    "Passage 2: \"To Kill a Mockingbird\" is a novel written by Harper Lee. It was published in 1960 and has since become a classic of American literature.\n",
    "\n",
    "Question 3: What is the largest country in the world by area?\n",
    "\n",
    "Passage 3: Russia is the largest country in the world by area. It covers more than 17 million square kilometers and spans 11 time zones.\n",
    "\n",
    "Question 4: What is the capital of France?\n",
    "\n",
    "Passage 4: Paris is the capital and most populous city of France. It is located in the north-central part of the country, and is known for its rich history, art, and culture.\n",
    "\n",
    "Question 5: Who was the first president of the United States?\n",
    "\n",
    "Passage 5: George Washington was the first president of the United States. He served from 1789 to 1797, and is widely regarded as one of the most important figures in American history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6801f50c974f4dd5b17e8bad8e970695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611277e11ba341718824e1f933a6736c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232e30ddd21b4915bcbec3690e78a793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ce831e0d644423b299ea16743a90f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8537b59461de45dda8e3e2ac1f8870e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/261M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: What is the capital of the United States?\n",
      "Passage 1: The capital of the United States is Washington, D.C. It is located on the east coast of the country, and is home to many important government buildings and monuments.\n",
      "Answer 1: Washington, D. C\n",
      "\n",
      "Question 2: Who wrote the novel \"To Kill a Mockingbird\"?\n",
      "Passage 2: \"To Kill a Mockingbird\" is a novel written by Harper Lee. It was published in 1960 and has since become a classic of American literature.\n",
      "Answer 2: Harper Lee\n",
      "\n",
      "Question 3: What is the largest country in the world by area?\n",
      "Passage 3: Russia is the largest country in the world by area. It covers more than 17 million square kilometers and spans 11 time zones.\n",
      "Answer 3: Russia\n",
      "\n",
      "Question 4: What is the capital of France?\n",
      "Passage 4: Paris is the capital and most populous city of France. It is located in the north-central part of the country, and is known for its rich history, art, and culture.\n",
      "Answer 4: Paris\n",
      "\n",
      "Question 5: Who was the first president of the United States?\n",
      "Passage 5: George Washington was the first president of the United States. He served from 1789 to 1797, and is widely regarded as one of the most important figures in American history.\n",
      "Answer 5: George Washington\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Solution for reference\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "\n",
    "# Load the QA model and tokenizer\n",
    "model_name = \"distilbert-base-cased-distilled-squad\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n",
    "\n",
    "# Define a set of questions and passages\n",
    "questions = [\n",
    "    \"What is the capital of the United States?\",\n",
    "    \"Who wrote the novel \\\"To Kill a Mockingbird\\\"?\",\n",
    "    \"What is the largest country in the world by area?\",\n",
    "    \"What is the capital of France?\",\n",
    "    \"Who was the first president of the United States?\"\n",
    "]\n",
    "passages = [\n",
    "    \"The capital of the United States is Washington, D.C. It is located on the east coast of the country, and is home to many important government buildings and monuments.\",\n",
    "    \"\\\"To Kill a Mockingbird\\\" is a novel written by Harper Lee. It was published in 1960 and has since become a classic of American literature.\",\n",
    "    \"Russia is the largest country in the world by area. It covers more than 17 million square kilometers and spans 11 time zones.\",\n",
    "    \"Paris is the capital and most populous city of France. It is located in the north-central part of the country, and is known for its rich history, art, and culture.\",\n",
    "    \"George Washington was the first president of the United States. He served from 1789 to 1797, and is widely regarded as one of the most important figures in American history.\"\n",
    "]\n",
    "\n",
    "# Loop over each question and passage, and use the QA model to find the answer\n",
    "for i, (question, passage) in enumerate(zip(questions, passages)):\n",
    "    # Encode the question and passage using the tokenizer\n",
    "    inputs = tokenizer.encode_plus(question, passage, return_tensors='pt', max_length=512, truncation_strategy='only_second')\n",
    "    input_ids = inputs['input_ids']\n",
    "    attention_mask = inputs['attention_mask']\n",
    "\n",
    "    # Pass the encoded input through the QA model\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, return_dict=True)\n",
    "    start_logits = outputs.start_logits\n",
    "    end_logits = outputs.end_logits\n",
    "\n",
    "\n",
    "    # Decode the predicted start and end positions to get the answer\n",
    "    start_index = torch.argmax(start_logits)\n",
    "    end_index = torch.argmax(end_logits) + 1\n",
    "\n",
    "    # Skip over any tokens before the start position or after the end position\n",
    "    for j, token_id in enumerate(input_ids[0]):\n",
    "        if j < start_index or j >= end_index:\n",
    "            input_ids[0][j] = tokenizer.pad_token_id\n",
    "\n",
    "    # Decode the answer from the corresponding tokens\n",
    "    answer_tokens = input_ids[0][start_index:end_index]\n",
    "    answer = tokenizer.decode(answer_tokens)\n",
    "\n",
    "    # Print the question, passage, and answer\n",
    "    print(\"Question {}: {}\".format(i+1, question))\n",
    "    print(\"Passage {}: {}\".format(i+1, passage))\n",
    "    print(\"Answer {}: {}\\n\".format(i+1, answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Use the QA code above\n",
    "\n",
    "Apply the code to one of Assignment 1 articles. Make a question, ground truth answer, and predict an answer using the code. Evaluate answer using precision/recall."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
